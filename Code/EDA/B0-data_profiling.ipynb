{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"automated_data_profiling.ipynb","provenance":[],"collapsed_sections":["2likfjZbYGHg"],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"YlAgo7G8YGGm","colab_type":"text"},"source":["# 1. Automated Data Profiling In Python"]},{"cell_type":"markdown","metadata":{"id":"GWESqEgVYGGp","colab_type":"text"},"source":["**Author : Anandakumar Varatharajah**\n","<br>\n","***http://www.analyticsinsights.ninja***"]},{"cell_type":"markdown","metadata":{"id":"jOb6iebqYGGq","colab_type":"text"},"source":["Version   : 0.17   \n","Date      : 14 July 2019  \n","License   : MIT License"]},{"cell_type":"markdown","metadata":{"id":"jOupKygYYGGr","colab_type":"text"},"source":["The main objective of this notebook is **only** to understand raw data profile. i.e. data type, min & max values, ranges, unique values, etc.  \n","In consequent notebooks we will explore further on how to make decisions to make the data tidy and perform the data transformations based on the understanding of the data profile.\n","<br>\n","The code is largely kept generic so that it could be used with any shape of data. "]},{"cell_type":"markdown","metadata":{"id":"tIya7MlyYGGs","colab_type":"text"},"source":["# The Game Changer - Data Profile Dataframe (DPD)"]},{"cell_type":"markdown","metadata":{"id":"DG49sv3UYGGt","colab_type":"text"},"source":["The game changer for exploratory data analysis is the final ***Data Profile Dataframe*** that is generated which combines ***all*** the information required to inform data cleaning, tidy data and optimisations (memory and processing) decisions.  \n","Instead of using various Pandas commands at different instances and going back and forth to cross refer information, Data Profile Dataframe brings all information into a single dataframe. This will be very useful when reviewing the data profile with the business subject matter or other team members as all information related to data profile is in a single easy to understand format.\n","\n","![image.png](https://raw.githubusercontent.com/AnalyticsInsightsNinja/Python_TidyData/master/SAMPLE_FULL_DPD_Image_MSWORD.PNG)\n"]},{"cell_type":"markdown","metadata":{"id":"OOysrluNYGGv","colab_type":"text"},"source":["Understanding the data is **the critical step** in preparing the data to be used for analytics. As many experts will point out the data preparation and transforming the data into a tidy format takes about 80% of the effort in any data analytics or data analysis project.<br>\n","***Understanding the data requires good understanding of the domain and/or access to a subject matter expert (SME) to help make decisions about data quality and data usage:***\n","* What are the columns and what do they mean?\n","* How to interpret each columns and possible values of a column?\n","* Should the columns be renamed (and cleaned e.g. trim)?\n","* Are there columns that may have similar information that could be dropped in favour of one master column?\n","* Can columns with no values (or all empty) be dropped?\n","* Can columns which have more than certain threshold of blank values be dropped?\n","* How can the missing values be filled and can it be filled meaningfully?\n","* Can rows that have missing values for certain columns or combination of columns be dropped? i.e. the row is meaningless wihtout those values.\n","* Can the numeric data type columns be converted / down casted to optimise memory usage based on the data values?\n","    - or will there be outliers possibly in future data sets that we cannot do this?\n","    - can the min and max values be used to determine the lowest possible data type?\n","* Can some string/object columns be converted to Category types?\n","    - based on count of unique values\n","* Can any columns be discarded that may not be required for analytics?"]},{"cell_type":"markdown","metadata":{"id":"fUQoEl3qYGGw","colab_type":"text"},"source":["# Environment setup"]},{"cell_type":"markdown","metadata":{"id":"O-ACv0uiYGGx","colab_type":"text"},"source":["It is recommended best practice to document the execution environment.  \n","e.g. When the initial version of this notebook was developed in Azure Notebooks (Jupyter) the environment was documented in the code. When the notebook was exported to local PC JupyterLab and then imported back into Azure Notebook, the Kernal changed to an older version and some code did not work. Having the initital versions documented in comments saved a lot of effort in trying to understand what went wrong.\n"]},{"cell_type":"code","metadata":{"id":"2dXkFH1aYZds","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592937788019,"user_tz":300,"elapsed":946,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"ff96a9b2-0163-46a5-fe6b-c5d07d109f4d"},"source":["#configuración en google colab de spark y pyspark\n","from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HLwD8Q4cYGGy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592937790828,"user_tz":300,"elapsed":685,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Get the date of execution\n","import datetime\n","date_generated = datetime.datetime.now()\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"xB4Ap6TkYGG5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592937792597,"user_tz":300,"elapsed":1216,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["from platform import python_version \n","# use python_version() to get the version. This is used in the final DPD HTML\n","# 3.6.6 in Azure Notebooks in April 2019\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTETzvnAYGG9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592937796732,"user_tz":300,"elapsed":2310,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["import pandas as pd\n","# use pd.__version__ to get the pandas version. This is used in the final DPD HTML\n","# Pandas version   0.22.0 in Azure Notebooks in April 2019\n","\n","# set maximum number of columns to display in notebook\n","pd.set_option('display.max_columns', 250)\n","\n","# To check whether a column is numeric type\n","from pandas.api.types import is_numeric_dtype\n","\n","# To check whether a column is object/string type\n","from pandas.api.types import is_string_dtype\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"YEHQbuiRYGHC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592937796735,"user_tz":300,"elapsed":1503,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["import numpy as np\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"5--AfsYxYGHH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1592937799723,"user_tz":300,"elapsed":1780,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"5a5dfb1c-14ba-4048-9317-fae467ccbfc2"},"source":["# Import the graph packages\n","import matplotlib.pyplot as plt\n","plt.rcParams.update({'figure.max_open_warning': 0})\n","%matplotlib inline\n","\n","import seaborn as sns\n","# Seabotn version   0.9.0 in Azure Notebooks in April 2019\n","# use sns.__version__ to get the pandas version. This is used in the final DPD HTML"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"uQG-QYHWYGHN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1592937808305,"user_tz":300,"elapsed":8023,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"f3fa96ab-cae2-438a-a5c9-9c54c2fe2b15"},"source":["# This library is required to generate the MS Word document\n","!pip install python-docx\n","from docx import Document\n","from docx.shared import Inches, Pt\n","from docx.enum.text import WD_ALIGN_PARAGRAPH  #used to align str(number) in cells "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: python-docx in /usr/local/lib/python3.6/dist-packages (0.8.10)\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from python-docx) (4.2.6)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VoHy8ge-YGHS","colab_type":"text"},"source":["# Raw data file exploration"]},{"cell_type":"markdown","metadata":{"id":"wEP7XS2zYGHT","colab_type":"text"},"source":["The raw data file used in this notebook has been derived from the Sales Products csv file from IBM Analytics Community and has been modified to include untidy data for the purposes of this data exploration work.  \n","The raw data should be in a format that can be laoded into pandas. i.e. if there are any rows need to be skipped,  column headers mapped, etc. should be handle in the pandas.read code block."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"-cYEyitmYGHU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592937905816,"user_tz":300,"elapsed":2110,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Download data file from Github site using curl and save it to local disk   -o \"filename\"\n","#!curl -o \"mydataset.csv\" \"https://raw.githubusercontent.com/AnalyticsInsightsNinja/Sample_Analytics_Data/master/titanic.csv\" \n","# Data file to be loaded\n","\n","raw_data_file = \"/content/gdrive/My Drive/calidad_de_vida_medellin/datasets/T2_ECV_sindum_sinout_ord.csv\" #\"mydataset.csv\""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFjt5jJ-YGHY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592937907104,"user_tz":300,"elapsed":1477,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Use Pandas to load the data file into a dataframe\n","try:\n","    df = pd.read_csv(raw_data_file, thousands=',', float_precision=2, delimiter = ';')\n","except:\n","    print(\"Error: Data file not found!\")\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhpD8Gt2bc1o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592937907780,"user_tz":300,"elapsed":1064,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"b7d3d059-0955-4556-fb66-5fee11d61af3"},"source":["df.shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9051, 94)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"E-WSbUu4ZFxm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592937910759,"user_tz":300,"elapsed":1076,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"66a2d038-b56f-4fec-e884-0b482860cd4c"},"source":["df.info()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9051 entries, 0 to 9050\n","Data columns (total 94 columns):\n"," #   Column      Non-Null Count  Dtype  \n","---  ------      --------------  -----  \n"," 0   Unnamed: 0  9051 non-null   int64  \n"," 1   p_12        9051 non-null   int64  \n"," 2   p_15a       9051 non-null   int64  \n"," 3   p_15b       9051 non-null   int64  \n"," 4   p_19a       9051 non-null   int64  \n"," 5   p_19b       9051 non-null   int64  \n"," 6   p_19c       9051 non-null   int64  \n"," 7   p_19d       9051 non-null   int64  \n"," 8   p_19e       9051 non-null   int64  \n"," 9   p_20a       9051 non-null   int64  \n"," 10  p_20b       9051 non-null   int64  \n"," 11  p_36a       9051 non-null   int64  \n"," 12  p_36b       9051 non-null   int64  \n"," 13  p_44        9051 non-null   int64  \n"," 14  p_45b       9051 non-null   int64  \n"," 15  p_45c       9051 non-null   int64  \n"," 16  p_45d       9051 non-null   int64  \n"," 17  p_45e       9051 non-null   int64  \n"," 18  p_45f       9051 non-null   int64  \n"," 19  p_49b       9051 non-null   int64  \n"," 20  p_49c       9051 non-null   int64  \n"," 21  p_66b       9051 non-null   int64  \n"," 22  p_66c       9051 non-null   int64  \n"," 23  p_66d       9051 non-null   int64  \n"," 24  p_67b       9051 non-null   int64  \n"," 25  p_67c       9051 non-null   int64  \n"," 26  p_68b       9051 non-null   int64  \n"," 27  p_68c       9051 non-null   int64  \n"," 28  p_83b       9051 non-null   int64  \n"," 29  p_83c       9051 non-null   int64  \n"," 30  p_83d       9051 non-null   int64  \n"," 31  p_83e       9051 non-null   int64  \n"," 32  p_83f       9051 non-null   int64  \n"," 33  p_84b       9051 non-null   int64  \n"," 34  p_84c       9051 non-null   int64  \n"," 35  p_84d       9051 non-null   int64  \n"," 36  p_86a       9051 non-null   int64  \n"," 37  p_86b       9051 non-null   int64  \n"," 38  p_86c       9051 non-null   int64  \n"," 39  p_86d       9051 non-null   int64  \n"," 40  p_86e       9051 non-null   int64  \n"," 41  p_86f       9051 non-null   int64  \n"," 42  p_86g       9051 non-null   int64  \n"," 43  p_86h       9051 non-null   int64  \n"," 44  p_86i       9051 non-null   int64  \n"," 45  p_125       9051 non-null   int64  \n"," 46  p_126       9051 non-null   int64  \n"," 47  p_157       9051 non-null   int64  \n"," 48  p_211       9051 non-null   int64  \n"," 49  p_212       9051 non-null   int64  \n"," 50  p_213       9051 non-null   int64  \n"," 51  p_214       9051 non-null   int64  \n"," 52  p_227       9051 non-null   int64  \n"," 53  p_232_gp    9051 non-null   float64\n"," 54  p_244_ip    9051 non-null   float64\n"," 55  p_5         9051 non-null   int64  \n"," 56  p_6         9051 non-null   int64  \n"," 57  p_7         9051 non-null   int64  \n"," 58  p_10        9051 non-null   int64  \n"," 59  p_43a       9051 non-null   int64  \n"," 60  p_43b       9051 non-null   int64  \n"," 61  p_43c       9051 non-null   int64  \n"," 62  p_43d       9051 non-null   int64  \n"," 63  p_146       9051 non-null   int64  \n"," 64  p_147       9051 non-null   int64  \n"," 65  p_148       9051 non-null   int64  \n"," 66  p_158       9051 non-null   int64  \n"," 67  p_162       9051 non-null   int64  \n"," 68  p_165       9051 non-null   int64  \n"," 69  p_171       9051 non-null   int64  \n"," 70  p_174       9051 non-null   int64  \n"," 71  p_178       9051 non-null   int64  \n"," 72  p_184       9051 non-null   int64  \n"," 73  p_258       9051 non-null   int64  \n"," 74  p_259       9051 non-null   int64  \n"," 75  p_260       9051 non-null   int64  \n"," 76  p_281       9051 non-null   int64  \n"," 77  p_282       9051 non-null   int64  \n"," 78  p_283       9051 non-null   int64  \n"," 79  p_284       9051 non-null   int64  \n"," 80  p_285       9051 non-null   int64  \n"," 81  p_286       9051 non-null   int64  \n"," 82  p_312       9051 non-null   int64  \n"," 83  p_313       9051 non-null   int64  \n"," 84  p_314       9051 non-null   int64  \n"," 85  p_315       9051 non-null   int64  \n"," 86  p_316       9051 non-null   int64  \n"," 87  p_317       9051 non-null   int64  \n"," 88  p_318       9051 non-null   int64  \n"," 89  p_319       9051 non-null   int64  \n"," 90  p_320       9051 non-null   int64  \n"," 91  p_321       9051 non-null   int64  \n"," 92  p_322       9051 non-null   int64  \n"," 93  p_323       9051 non-null   int64  \n","dtypes: float64(2), int64(92)\n","memory usage: 6.5 MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E92Z-Rruf8nl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938121378,"user_tz":300,"elapsed":860,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["df.iloc[:, :56] = df.iloc[:, :56].astype(float)\n","df.iloc[:, 56:] = df.iloc[:, 56:].astype(object)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"2GLSiRYTgpae","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592938124358,"user_tz":300,"elapsed":1017,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"1f1387a3-efea-4a9f-f395-c0ced1b7b584"},"source":["df.info()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9051 entries, 0 to 9050\n","Data columns (total 94 columns):\n"," #   Column      Non-Null Count  Dtype  \n","---  ------      --------------  -----  \n"," 0   Unnamed: 0  9051 non-null   float64\n"," 1   p_12        9051 non-null   float64\n"," 2   p_15a       9051 non-null   float64\n"," 3   p_15b       9051 non-null   float64\n"," 4   p_19a       9051 non-null   float64\n"," 5   p_19b       9051 non-null   float64\n"," 6   p_19c       9051 non-null   float64\n"," 7   p_19d       9051 non-null   float64\n"," 8   p_19e       9051 non-null   float64\n"," 9   p_20a       9051 non-null   float64\n"," 10  p_20b       9051 non-null   float64\n"," 11  p_36a       9051 non-null   float64\n"," 12  p_36b       9051 non-null   float64\n"," 13  p_44        9051 non-null   float64\n"," 14  p_45b       9051 non-null   float64\n"," 15  p_45c       9051 non-null   float64\n"," 16  p_45d       9051 non-null   float64\n"," 17  p_45e       9051 non-null   float64\n"," 18  p_45f       9051 non-null   float64\n"," 19  p_49b       9051 non-null   float64\n"," 20  p_49c       9051 non-null   float64\n"," 21  p_66b       9051 non-null   float64\n"," 22  p_66c       9051 non-null   float64\n"," 23  p_66d       9051 non-null   float64\n"," 24  p_67b       9051 non-null   float64\n"," 25  p_67c       9051 non-null   float64\n"," 26  p_68b       9051 non-null   float64\n"," 27  p_68c       9051 non-null   float64\n"," 28  p_83b       9051 non-null   float64\n"," 29  p_83c       9051 non-null   float64\n"," 30  p_83d       9051 non-null   float64\n"," 31  p_83e       9051 non-null   float64\n"," 32  p_83f       9051 non-null   float64\n"," 33  p_84b       9051 non-null   float64\n"," 34  p_84c       9051 non-null   float64\n"," 35  p_84d       9051 non-null   float64\n"," 36  p_86a       9051 non-null   float64\n"," 37  p_86b       9051 non-null   float64\n"," 38  p_86c       9051 non-null   float64\n"," 39  p_86d       9051 non-null   float64\n"," 40  p_86e       9051 non-null   float64\n"," 41  p_86f       9051 non-null   float64\n"," 42  p_86g       9051 non-null   float64\n"," 43  p_86h       9051 non-null   float64\n"," 44  p_86i       9051 non-null   float64\n"," 45  p_125       9051 non-null   float64\n"," 46  p_126       9051 non-null   float64\n"," 47  p_157       9051 non-null   float64\n"," 48  p_211       9051 non-null   float64\n"," 49  p_212       9051 non-null   float64\n"," 50  p_213       9051 non-null   float64\n"," 51  p_214       9051 non-null   float64\n"," 52  p_227       9051 non-null   float64\n"," 53  p_232_gp    9051 non-null   float64\n"," 54  p_244_ip    9051 non-null   float64\n"," 55  p_5         9051 non-null   float64\n"," 56  p_6         9051 non-null   object \n"," 57  p_7         9051 non-null   object \n"," 58  p_10        9051 non-null   object \n"," 59  p_43a       9051 non-null   object \n"," 60  p_43b       9051 non-null   object \n"," 61  p_43c       9051 non-null   object \n"," 62  p_43d       9051 non-null   object \n"," 63  p_146       9051 non-null   object \n"," 64  p_147       9051 non-null   object \n"," 65  p_148       9051 non-null   object \n"," 66  p_158       9051 non-null   object \n"," 67  p_162       9051 non-null   object \n"," 68  p_165       9051 non-null   object \n"," 69  p_171       9051 non-null   object \n"," 70  p_174       9051 non-null   object \n"," 71  p_178       9051 non-null   object \n"," 72  p_184       9051 non-null   object \n"," 73  p_258       9051 non-null   object \n"," 74  p_259       9051 non-null   object \n"," 75  p_260       9051 non-null   object \n"," 76  p_281       9051 non-null   object \n"," 77  p_282       9051 non-null   object \n"," 78  p_283       9051 non-null   object \n"," 79  p_284       9051 non-null   object \n"," 80  p_285       9051 non-null   object \n"," 81  p_286       9051 non-null   object \n"," 82  p_312       9051 non-null   object \n"," 83  p_313       9051 non-null   object \n"," 84  p_314       9051 non-null   object \n"," 85  p_315       9051 non-null   object \n"," 86  p_316       9051 non-null   object \n"," 87  p_317       9051 non-null   object \n"," 88  p_318       9051 non-null   object \n"," 89  p_319       9051 non-null   object \n"," 90  p_320       9051 non-null   object \n"," 91  p_321       9051 non-null   object \n"," 92  p_322       9051 non-null   object \n"," 93  p_323       9051 non-null   object \n","dtypes: float64(56), object(38)\n","memory usage: 6.5+ MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zN1PVe4fYGHb","colab_type":"text"},"source":["**Note:** If the raw data is a big data file of several GB's in size it may not be possible to load the the whole file into memory. One possibility is using 'pandas pyspark'.<br>\n","Other options to load data incrementally and optimise the data by converting data types will be demonstrated in a seperate notebook."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Hk7uBkmsYGHc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"ok","timestamp":1592938134141,"user_tz":300,"elapsed":1334,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"e330d41e-a23d-4556-ad3a-2bedcb53e1b4"},"source":["# Sample raw data rows from dataset\n","df.sample(5).round(2)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>p_12</th>\n","      <th>p_15a</th>\n","      <th>p_15b</th>\n","      <th>p_19a</th>\n","      <th>p_19b</th>\n","      <th>p_19c</th>\n","      <th>p_19d</th>\n","      <th>p_19e</th>\n","      <th>p_20a</th>\n","      <th>p_20b</th>\n","      <th>p_36a</th>\n","      <th>p_36b</th>\n","      <th>p_44</th>\n","      <th>p_45b</th>\n","      <th>p_45c</th>\n","      <th>p_45d</th>\n","      <th>p_45e</th>\n","      <th>p_45f</th>\n","      <th>p_49b</th>\n","      <th>p_49c</th>\n","      <th>p_66b</th>\n","      <th>p_66c</th>\n","      <th>p_66d</th>\n","      <th>p_67b</th>\n","      <th>p_67c</th>\n","      <th>p_68b</th>\n","      <th>p_68c</th>\n","      <th>p_83b</th>\n","      <th>p_83c</th>\n","      <th>p_83d</th>\n","      <th>p_83e</th>\n","      <th>p_83f</th>\n","      <th>p_84b</th>\n","      <th>p_84c</th>\n","      <th>p_84d</th>\n","      <th>p_86a</th>\n","      <th>p_86b</th>\n","      <th>p_86c</th>\n","      <th>p_86d</th>\n","      <th>p_86e</th>\n","      <th>p_86f</th>\n","      <th>p_86g</th>\n","      <th>p_86h</th>\n","      <th>p_86i</th>\n","      <th>p_125</th>\n","      <th>p_126</th>\n","      <th>p_157</th>\n","      <th>p_211</th>\n","      <th>p_212</th>\n","      <th>p_213</th>\n","      <th>p_214</th>\n","      <th>p_227</th>\n","      <th>p_232_gp</th>\n","      <th>p_244_ip</th>\n","      <th>p_5</th>\n","      <th>p_6</th>\n","      <th>p_7</th>\n","      <th>p_10</th>\n","      <th>p_43a</th>\n","      <th>p_43b</th>\n","      <th>p_43c</th>\n","      <th>p_43d</th>\n","      <th>p_146</th>\n","      <th>p_147</th>\n","      <th>p_148</th>\n","      <th>p_158</th>\n","      <th>p_162</th>\n","      <th>p_165</th>\n","      <th>p_171</th>\n","      <th>p_174</th>\n","      <th>p_178</th>\n","      <th>p_184</th>\n","      <th>p_258</th>\n","      <th>p_259</th>\n","      <th>p_260</th>\n","      <th>p_281</th>\n","      <th>p_282</th>\n","      <th>p_283</th>\n","      <th>p_284</th>\n","      <th>p_285</th>\n","      <th>p_286</th>\n","      <th>p_312</th>\n","      <th>p_313</th>\n","      <th>p_314</th>\n","      <th>p_315</th>\n","      <th>p_316</th>\n","      <th>p_317</th>\n","      <th>p_318</th>\n","      <th>p_319</th>\n","      <th>p_320</th>\n","      <th>p_321</th>\n","      <th>p_322</th>\n","      <th>p_323</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2281</th>\n","      <td>2281.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>-88.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>10.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>800000.0</td>\n","      <td>350000.0</td>\n","      <td>1.0</td>\n","      <td>9</td>\n","      <td>904</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>19</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>614</th>\n","      <td>614.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>-88.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>-88.0</td>\n","      <td>-88.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>460000.0</td>\n","      <td>1000000.0</td>\n","      <td>500000.0</td>\n","      <td>1.0</td>\n","      <td>16</td>\n","      <td>1613</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>227</th>\n","      <td>227.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-88.0</td>\n","      <td>-88.0</td>\n","      <td>3.0</td>\n","      <td>10.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>750000.0</td>\n","      <td>2000000.0</td>\n","      <td>600000.0</td>\n","      <td>1.0</td>\n","      <td>7</td>\n","      <td>706</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1453</th>\n","      <td>1453.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>-88.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>20000.0</td>\n","      <td>-99.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>16</td>\n","      <td>1607</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>-98</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>-88</td>\n","      <td>19</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>8399</th>\n","      <td>8399.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>-88.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>200000.0</td>\n","      <td>219000.0</td>\n","      <td>1.0</td>\n","      <td>7</td>\n","      <td>717</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>-98</td>\n","      <td>-98</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>19</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0  p_12  p_15a  p_15b  p_19a  p_19b  p_19c  p_19d  p_19e  \\\n","2281      2281.0   1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0   \n","614        614.0   1.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0   \n","227        227.0   1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0   \n","1453      1453.0   2.0    0.0    2.0    0.0    0.0    0.0    1.0    1.0   \n","8399      8399.0   5.0    2.0    3.0    0.0    0.0    1.0    2.0    2.0   \n","\n","      p_20a  p_20b  p_36a  p_36b  p_44  p_45b  p_45c  p_45d  p_45e  p_45f  \\\n","2281    1.0    0.0    0.0    1.0 -88.0    0.0    0.0    1.0    0.0    0.0   \n","614     1.0    0.0    0.0    1.0 -88.0    0.0    0.0    1.0    0.0    0.0   \n","227     0.0    1.0    1.0    0.0   1.0    0.0    0.0    0.0    1.0    0.0   \n","1453    2.0    0.0    0.0    2.0 -88.0    1.0    0.0    0.0    1.0    0.0   \n","8399    5.0    0.0    0.0    5.0 -88.0    3.0    0.0    1.0    0.0    0.0   \n","\n","      p_49b  p_49c  p_66b  p_66c  p_66d  p_67b  p_67c  p_68b  p_68c  p_83b  \\\n","2281    0.0    1.0    1.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0   \n","614     1.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    1.0    0.0   \n","227     0.0    1.0    1.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0   \n","1453    1.0    0.0    1.0    1.0    0.0    0.0    2.0    0.0    2.0    0.0   \n","8399    5.0    0.0    1.0    1.0    3.0    1.0    4.0    0.0    5.0    0.0   \n","\n","      p_83c  p_83d  p_83e  p_83f  p_84b  p_84c  p_84d  p_86a  p_86b  p_86c  \\\n","2281    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0   \n","614     0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n","227     1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0   \n","1453    1.0    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0   \n","8399    2.0    0.0    0.0    0.0    1.0    1.0    0.0    3.0    1.0    0.0   \n","\n","      p_86d  p_86e  p_86f  p_86g  p_86h  p_86i  p_125  p_126  p_157  p_211  \\\n","2281    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0   10.0   \n","614     0.0    0.0    0.0    0.0    1.0    0.0  -88.0  -88.0    2.0    5.0   \n","227     0.0    0.0    0.0    0.0    0.0    0.0  -88.0  -88.0    3.0   10.0   \n","1453    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    4.0    9.0   \n","8399    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    7.0   14.0   \n","\n","      p_212  p_213  p_214     p_227   p_232_gp  p_244_ip  p_5 p_6   p_7 p_10  \\\n","2281    1.0    0.0    0.0       0.0   800000.0  350000.0  1.0   9   904    4   \n","614     0.0    0.0    0.0  460000.0  1000000.0  500000.0  1.0  16  1613    3   \n","227     1.0    0.0    1.0  750000.0  2000000.0  600000.0  1.0   7   706    3   \n","1453    0.0    0.0    0.0   20000.0      -99.0       0.0  1.0  16  1607    3   \n","8399    0.0    0.0    0.0       0.0   200000.0  219000.0  1.0   7   717    2   \n","\n","     p_43a p_43b p_43c p_43d p_146 p_147 p_148 p_158 p_162 p_165 p_171 p_174  \\\n","2281     0     0     0     0     5    10     4     1     1     1     1     1   \n","614      0     0     0     0     4    10     4     1     1     1     1     1   \n","227      0     0     0     1     4    10     4     1     1     1     1     1   \n","1453     0     0     0     0     5    10     4     1     1     1     1     1   \n","8399     0     0     0     0     5     9     4     1     1     1     1     1   \n","\n","     p_178 p_184 p_258 p_259 p_260 p_281 p_282 p_283 p_284 p_285 p_286 p_312  \\\n","2281     1     6     2     4     2     3     3     2     2    14    19     4   \n","614      2     6     1     3     3     4     4     2     7     1    19     2   \n","227      1     6     2     4     1     5     3     2     2    14    19     3   \n","1453     2     6   -98     4     3     4     2     2    14   -88    19     4   \n","8399     1     6   -98   -98     2     3     3     2     2    14    19     4   \n","\n","     p_313 p_314 p_315 p_316 p_317 p_318 p_319 p_320 p_321 p_322 p_323  \n","2281     2     3     4     4     4     4     4     1     5     4     5  \n","614      3     2     3     3     3     4     4     4     4     4     3  \n","227      2     4     4     5     4     4     4     4     4     4     4  \n","1453     4     4     4     4     5     4     3     4     4     4     3  \n","8399     3     4     2     3     4     2     2     3     4     3     4  "]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"2likfjZbYGHg","colab_type":"text"},"source":["# Memory Usage Analysis"]},{"cell_type":"code","metadata":{"id":"IbyZmnBcYGHh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938138238,"user_tz":300,"elapsed":1670,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Check whether the file is obatined from url.\n","# If from url, then skip file size in disk check\n","\n","if \"http\" in raw_data_file:\n","    file_size = float('nan')\n","else:\n","    # Calculating file size (in MB) on disk\n","    import os\n","\n","    file_size = (os.stat(raw_data_file).st_size / 1024 **2)\n","    #This is used in the DPD HTML\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"I--gxwCrYGHl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938138240,"user_tz":300,"elapsed":1231,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Calculate dataset size in memory (MB)\n","df_mem = df.memory_usage(deep=True).sum() / 1024**2\n","#This is used in the DPD HTML\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"lyW3kVwgYGHp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938139253,"user_tz":300,"elapsed":1184,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Calclulate dataset size increase in memory (MB)\n","sz_increase = ((df_mem - file_size) / file_size)\n","#This is used in the DPD HTML"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLH7oWCsYGHt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938140044,"user_tz":300,"elapsed":1524,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Plot the memory usage \n","# Create a dictionary from the variables and convert to Pandas DataFrame\n","# Use DataFrame's ploting capabilities\n","raw_data_dict = {\"File on disk\":file_size, \"Dataset in memroy\": df_mem}\n","raw_data_plot = pd.DataFrame.from_dict(raw_data_dict, orient='index').reset_index()\n","\n","# Pandas DataFrame plot\n","raw_data_plot.plot(kind='bar',\\\n","                   x=\"index\" ,\\\n","                   y=0, \\\n","                   legend=False, \\\n","                   title='Data size increase from disk to memory')\n","# plt.subplots_adjust(wspace=0.4, hspace=0.35)\n","plt.xticks(rotation=0)\n","\n","# Save the figure\n","plt.savefig('fig_df_tot_memory.png', dpi=50)\n","plt.close('all')\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"byTPcTknYGHx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938140046,"user_tz":300,"elapsed":1128,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Get memory used by each column in the raw data dataset in MB\n","# This will be later merged with the DPD\n","mem_used_dtypes = pd.DataFrame(df.memory_usage(deep=True) / 1024**2)\n","\n","# Rename column\n","mem_used_dtypes.rename(columns={ 0:'memory'}, inplace=True)\n","\n","# Drop index memory usage since this is not required when merging with Data Quality Dataframe\n","mem_used_dtypes.drop('Index', axis=0, inplace=True) \n"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I-ePgI1uYGH1","colab_type":"text"},"source":["# Constructing The Data Profile Dataframe (DPD) - The Game Changer "]},{"cell_type":"code","metadata":{"id":"1uAlMqN7YGH1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938143379,"user_tz":300,"elapsed":1966,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Number of rows of the DPD will be the count of columns in the raw date dataframe\n","# Since it there will be one row for each column\n","no_of_rows = len(df.columns)\n","\n","\n","# Constructing the data_qlt_df dataframe and pre-assigning and columns\n","# Pre-assigning the number of rows the dataframe would have is memory and processing efficient\n","# This is a better approach than continuous append or concat operation to dataframe\n","\n","data_qlt_df = pd.DataFrame(index=np.arange(0, no_of_rows), \\\n","                            columns=('column_name', 'col_data_type', 'col_memory','non_null_values', \\\n","                                     'unique_values_count', 'column_dtype')\n","                          )\n","\n","\n","# Add rows to the data_qlt_df dataframe\n","for ind, cols in enumerate(df.columns):\n","    # Count of unique values in the column\n","    col_unique_count = df[cols].nunique()\n","    \n","    data_qlt_df.loc[ind] = [cols, \\\n","                            df[cols].dtype, \\\n","                            mem_used_dtypes['memory'][ind], \\\n","                            df[cols].count(), \\\n","                            col_unique_count, \\\n","                            cols + '~'+ str(df[cols].dtype)\n","                            ]\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zt2EoRhtYGH6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938144469,"user_tz":300,"elapsed":2581,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Use describe() to get column stats of raw dataframe\n","# This will be merged with the DPD\n","raw_num_df = df.describe().T.round(2)\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"vR_pi3EUYGH9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938144473,"user_tz":300,"elapsed":2179,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["#----- Key Step ---------------\n","# Merging the df.describe() output with rest of the info to create a single Data Profile Dataframe\n","data_qlt_df = pd.merge(data_qlt_df, raw_num_df, how='left', left_on='column_name', right_index=True)\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZFbrFckYGIA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938145072,"user_tz":300,"elapsed":762,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Calculate percentage of non-null values over total number of values\n","data_qlt_df['%_of_non_nulls'] = (data_qlt_df['non_null_values']/df.shape[0])*100\n","\n","# Calculate null values for the column\n","data_qlt_df['null_values'] = df.shape[0] - data_qlt_df['non_null_values']\n","\n","# Calculate percentage of null values over total number of values\n","data_qlt_df['%_of_nulls'] = 100 - data_qlt_df['%_of_non_nulls']\n","\n","# Calculate percentage of each column memory usage compared to total memory used by raw data datframe\n","data_qlt_df['%_of_total_memory'] = data_qlt_df['col_memory'] / data_qlt_df['col_memory'].sum() * 100\n","\n","# Calculate the total memory used by a given group of data type\n","# See Notes section at the bottom of this notebook for advatages of using 'transform' function with group_by\n","data_qlt_df[\"dtype_total\"] = data_qlt_df.groupby('col_data_type')[\"col_memory\"].transform('sum')\n","\n","# Calculate the percentage memory used by each column data type compared to the total memory used by the group of data type\n","# the above can be merged to one calculation if we do not need the total as separate column\n","#data_qlt_df[\"%_of_dtype_mem2\"] = data_qlt_df[\"Dtype Memory\"] / (data_qlt_df.groupby('Data Type')[\"Dtype Memory\"].transform('sum')) * 100\n","data_qlt_df[\"%_of_dtype_mem\"] = data_qlt_df[\"col_memory\"] / data_qlt_df[\"dtype_total\"] * 100\n","\n","# Calculate the percentage memory used by each group of data type of the total memory used by dataset\n","data_qlt_df[\"dtype_%_total_mem\"] = data_qlt_df[\"dtype_total\"] / df_mem * 100\n","\n","# Calculate the count of each data type\n","data_qlt_df[\"dtype_count\"] = data_qlt_df.groupby('col_data_type')[\"col_data_type\"].transform('count')\n","\n","# Calculate the total count of column values\n","data_qlt_df[\"count\"] = data_qlt_df['null_values'] + data_qlt_df['non_null_values']"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmCwbUfTYGID","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938146539,"user_tz":300,"elapsed":1124,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Reorder the Data Profile Dataframe columns\n","data_qlt_df = data_qlt_df[\n","                            ['column_name', 'col_data_type', 'col_memory', '%_of_dtype_mem', '%_of_total_memory',\\\n","                             'dtype_count', 'dtype_total', 'dtype_%_total_mem', 'non_null_values', '%_of_non_nulls',\\\n","                             'null_values', '%_of_nulls', 'unique_values_count', 'count', 'mean', 'std', 'min', '25%',\\\n","                             '50%', '75%', 'max']\n","                         ]\n"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-Tb4Nt7YGIG","colab_type":"text"},"source":["**The above data quality data frame summarises all information required for making data quality decisions.**  \n","Though there are info() and describe() methods to do these, having all the relvant information in one dataframe makes the data quality exploration much easier. This dataframe can be used for summarising information and for plotting to ehnace the ease of Data Understanding effort."]},{"cell_type":"markdown","metadata":{"id":"hzmOqHcRYGIG","colab_type":"text"},"source":["# Plot Memory Usage Analysis"]},{"cell_type":"code","metadata":{"id":"yn0tiMLWYGIH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1592938149982,"user_tz":300,"elapsed":1962,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"f544f208-47f5-410b-b728-d7c29d951b56"},"source":["# Plot count of column data types and memory used by each datatype\n","plt_dtype = data_qlt_df.groupby('col_data_type')['dtype_count', 'dtype_total', 'dtype_%_total_mem'].last().sort_values(by='dtype_count')\n","\n","fig1, (ax, ax2) = plt.subplots(ncols=2, figsize=(10,5))\n","plt.subplots_adjust(wspace=0.4, hspace=0.35, bottom=0.20)\n","\n","plt_dtype.plot(kind='bar', y='dtype_count',  use_index=True, legend=False, ax=ax, title='Count of columns by data type')\n","\n","plt_dtype.plot(kind='bar', y='dtype_total',  use_index=True, legend=False, ax=ax2, title='Memory used by data type')\n","\n","fig1.savefig(\"fig_cols_memory.png\", dpi=50)\n","plt.close('all')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"VfN66aIKYGIK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938149983,"user_tz":300,"elapsed":1095,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Memory used by columns of raw data dataframe\n","fig2, ax = plt.subplots(ncols=1, figsize=(15,5))\n","plt.subplots_adjust(wspace=0.4, hspace=0.35, bottom=0.30)\n","\n","# Memory used by object data type\n","(data_qlt_df[data_qlt_df['col_data_type'] == 'object']\n"," .sort_values(by='col_memory', ascending=False)\n"," .plot(kind=\"bar\", \n","       x=\"column_name\", \n","       y=\"col_memory\", \n","       title=\"Memory (MB) usage by columns of object data type\",\n","      legend=False, ax=ax)\n",")\n","plt.xticks(rotation=35)\n","fig2.savefig(\"fig_object_cols_memory.png\", dpi=50)\n","plt.close('all')\n","\n","# Memory used by non-object data type\n","fig2, ax1 = plt.subplots(ncols=1, figsize=(15,5))\n","plt.subplots_adjust(wspace=0.4, hspace=0.35, bottom=0.30)\n","\n","(data_qlt_df[data_qlt_df['col_data_type'] != 'object']\n"," .sort_values(by='col_memory', ascending=False)\n"," .plot(kind=\"bar\", \n","       x=\"column_name\", \n","       y=\"col_memory\", \n","       title=\"Memory (MB) usage by columns of non-object data type\",\n","      legend=False, ax=ax1)\n",")\n","plt.xticks(rotation=35)\n","\n","fig2.savefig(\"fig_non_object_cols_memory.png\", dpi=50)\n","plt.close('all')\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjTLVrryajIM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938152136,"user_tz":300,"elapsed":1310,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["df = df.drop(['Unnamed: 0'], axis=1)"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nVlQnaVBYGIN","colab_type":"text"},"source":["# Generate data profile graphs for 'numerical' columns"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"vylN5AHfYGIN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":995},"executionInfo":{"status":"ok","timestamp":1592938189638,"user_tz":300,"elapsed":36157,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"ded303e2-0156-4959-e435-a47f40a44e69"},"source":["import numpy as np\n","from matplotlib.patches import Rectangle\n","\n","# Get the list of numeric columns from raw dataframe\n","# need this: from pandas.api.types import is_numeric_dtype\n","# get numeric columns which are not empty\n","num_cols = [cols for cols in df.columns if is_numeric_dtype(df[cols]) and len(df[cols].dropna())>0]\n","\n","iter_len = len(num_cols)\n","\n","# For each numeric column in the list\n","for x, col_name in enumerate(num_cols):\n","    print(x+1, \" of \", iter_len, \" completed   \",  col_name)\n","    \n","    # Create a copy of the column values without nulls or NA\n","    no_null_col = df[col_name].dropna()\n","    \n","    \n","    # Calculate the 95 percentile of the values\n","    q25 = np.percentile(no_null_col, 25)\n","    q75 = np.percentile(no_null_col, 75)    \n","    q95 = np.percentile(no_null_col, 95)\n","    \n","    # Plot the graphs\n","    fig3 = plt.figure(figsize=(20,15))\n","    fig3.suptitle(\"Profile of column  \" + col_name, fontsize=25)  #Title for the whole figure\n","    plt.subplots_adjust(wspace=0.4, hspace=0.35)\n","\n","    ax1 = fig3.add_subplot(2,3,1)\n","    ax1.set_title(\"Box plot for all the values\", fontsize=20)\n","    plt.setp(ax1.get_xticklabels(), ha=\"right\", rotation=35)\n","    plt.setp(ax1.get_yticklabels(), ha=\"right\", fontsize=15)\n","    ax1.boxplot(no_null_col)\n","\n","    ax1 = fig3.add_subplot(2,3,2)\n","    ax1.set_title(\"Distribution of all values\", fontsize=20)\n","    plt.setp(ax1.get_xticklabels(), ha=\"right\", rotation=35, fontsize=15)\n","    plt.setp(ax1.get_yticklabels(), ha=\"right\", fontsize=15)\n","    ax1.hist(no_null_col)\n","\n","    ax1 = fig3.add_subplot(2,3,3)\n","    ax1.set_title(\"Boxplot for quartiles (all values)\", fontsize=20)\n","    if len(no_null_col.value_counts()) >= 4:\n","        df[u'quartiles'] = pd.qcut(\n","                        df[col_name],\n","                        4, duplicates='drop')\n","        df.boxplot(column= col_name, by=u'quartiles', ax = ax1)\n","    plt.setp(ax1.get_xticklabels(), ha=\"right\", rotation=35, fontsize=15)\n","    plt.setp(ax1.get_yticklabels(), ha=\"right\", fontsize=15)\n","\n","    ax1 = fig3.add_subplot(2,3,4)\n","    ax1.set_title(\"Box plot without outliers\", fontsize=20)\n","    plt.setp(ax1.get_xticklabels(), ha=\"right\", rotation=35, fontsize=15)\n","    plt.setp(ax1.get_yticklabels(), ha=\"right\", fontsize=15)\n","    ax1.boxplot(no_null_col, showfliers=False)\n","\n","    ax1 = fig3.add_subplot(2,3,5)\n","    ax1.set_title(\"Violin plot (<95% percentile)\", fontsize=20)\n","    plt.setp(ax1.get_xticklabels(), ha=\"right\", rotation=35, fontsize=15)\n","    plt.setp(ax1.get_yticklabels(), ha=\"right\", fontsize=15)\n","    ax1.violinplot(no_null_col[no_null_col <= q95])\n","\n","    \n","    #Histogram with bin ranges, counts and percentile color\n","    ax1 = fig3.add_subplot(2,3,6)\n","    ax1.set_title(\"Histogram (<95% percentile)\", fontsize=20)\n","    plt.setp(ax1.get_xticklabels(), ha=\"right\", rotation=35, fontsize=15)\n","    plt.setp(ax1.get_yticklabels(), ha=\"right\", fontsize=15)\n","\n","    # Take only the data less than 95 percentile\n","    data = no_null_col[no_null_col <= q95]\n","\n","    # Colours for different percentiles\n","    perc_25_colour = 'gold'\n","    perc_50_colour = 'mediumaquamarine'\n","    perc_75_colour = 'deepskyblue'\n","    perc_95_colour = 'peachpuff'\n","\n","    '''\n","    counts  = numpy.ndarray of count of data ponts for each bin/column in the histogram\n","    bins    = numpy.ndarray of bin edge/range values\n","    patches = a list of Patch objects.\n","            each Patch object contains a Rectnagle object. \n","            e.g. Rectangle(xy=(-2.51953, 0), width=0.501013, height=3, angle=0)\n","    '''\n","    counts, bins, patches = ax1.hist(data, bins=10, facecolor=perc_50_colour, edgecolor='gray')\n","\n","    # Set the ticks to be at the edges of the bins.\n","    ax1.set_xticks(bins.round(2))\n","    plt.xticks(rotation=70, fontsize=15)\n","\n","    # Change the colors of bars at the edges\n","    for patch, leftside, rightside in zip(patches, bins[:-1], bins[1:]):\n","        if rightside < q25:\n","            patch.set_facecolor(perc_25_colour)\n","        elif leftside > q95:\n","            patch.set_facecolor(perc_95_colour)\n","        elif leftside > q75:\n","            patch.set_facecolor(perc_75_colour)\n","\n","    # Calculate bar centre to display the count of data points and %\n","    bin_x_centers = 0.5 * np.diff(bins) + bins[:-1]\n","    bin_y_centers = ax1.get_yticks()[1] * 0.25\n","\n","    # Display the the count of data points and % for each bar in histogram\n","    for i in range(len(bins)-1):\n","        bin_label = \"{0:,}\".format(counts[i]) + \"  ({0:,.2f}%)\".format((counts[i]/counts.sum())*100)\n","        plt.text(bin_x_centers[i], bin_y_centers, bin_label, rotation=90, rotation_mode='anchor')\n","\n","    #create legend\n","    handles = [Rectangle((0,0),1,1,color=c,ec=\"k\") for c in [perc_25_colour, perc_50_colour, perc_75_colour, perc_95_colour]]\n","    labels= [\"0-25 Percentile\",\"25-50 Percentile\", \"50-75 Percentile\", \">95 Percentile\"]\n","    plt.legend(handles, labels, bbox_to_anchor=(0.5, 0., 0.85, 0.99))\n","    \n","\n","    fig3.suptitle(\"Profile of column  \" + col_name, fontsize=25)  #Title for the whole figure\n","    fig_name = 'fig_' + col_name\n","    fig3.savefig(fig_name, dpi=50)\n","    plt.close('all')\n","    \n","#     plt.show()\n","\n","df.drop(u'quartiles', axis=1, inplace=True)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["1  of  55  completed    p_12\n","2  of  55  completed    p_15a\n","3  of  55  completed    p_15b\n","4  of  55  completed    p_19a\n","5  of  55  completed    p_19b\n","6  of  55  completed    p_19c\n","7  of  55  completed    p_19d\n","8  of  55  completed    p_19e\n","9  of  55  completed    p_20a\n","10  of  55  completed    p_20b\n","11  of  55  completed    p_36a\n","12  of  55  completed    p_36b\n","13  of  55  completed    p_44\n","14  of  55  completed    p_45b\n","15  of  55  completed    p_45c\n","16  of  55  completed    p_45d\n","17  of  55  completed    p_45e\n","18  of  55  completed    p_45f\n","19  of  55  completed    p_49b\n","20  of  55  completed    p_49c\n","21  of  55  completed    p_66b\n","22  of  55  completed    p_66c\n","23  of  55  completed    p_66d\n","24  of  55  completed    p_67b\n","25  of  55  completed    p_67c\n","26  of  55  completed    p_68b\n","27  of  55  completed    p_68c\n","28  of  55  completed    p_83b\n","29  of  55  completed    p_83c\n","30  of  55  completed    p_83d\n","31  of  55  completed    p_83e\n","32  of  55  completed    p_83f\n","33  of  55  completed    p_84b\n","34  of  55  completed    p_84c\n","35  of  55  completed    p_84d\n","36  of  55  completed    p_86a\n","37  of  55  completed    p_86b\n","38  of  55  completed    p_86c\n","39  of  55  completed    p_86d\n","40  of  55  completed    p_86e\n","41  of  55  completed    p_86f\n","42  of  55  completed    p_86g\n","43  of  55  completed    p_86h\n","44  of  55  completed    p_86i\n","45  of  55  completed    p_125\n","46  of  55  completed    p_126\n","47  of  55  completed    p_157\n","48  of  55  completed    p_211\n","49  of  55  completed    p_212\n","50  of  55  completed    p_213\n","51  of  55  completed    p_214\n","52  of  55  completed    p_227\n","53  of  55  completed    p_232_gp\n","54  of  55  completed    p_244_ip\n","55  of  55  completed    p_5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3u9pavnMYGIR","colab_type":"text"},"source":["# Generate data profile graphs for 'object' columns"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"GqwFLvjAYGIR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":692},"executionInfo":{"status":"ok","timestamp":1592938196413,"user_tz":300,"elapsed":38288,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"b21b0df8-66d2-4925-e1a6-bb30b551a421"},"source":["# Get the list of object columns from raw dataframe\n","# get object columns which are not empty\n","obj_cols = [cols for cols in df.columns if is_string_dtype(df[cols]) and len(df[cols].dropna())>0]\n","\n","iter_len = len(obj_cols)\n","\n","\n","# For each object column in the list\n","for x, col_name in enumerate(obj_cols):\n","    print(x+1, \" of \", iter_len, \" completed   \",  col_name)\n","    \n","    # Create a copy of the column values without nulls or NA\n","    no_null_col = df[col_name].dropna()\n","\n","    values_freq_threshold = 25\n","    col_unique_count = df[col_name].nunique()\n","    \n","    # If unique values count is below the threshold value then store the details of unique values\n","    col_unique_vals = df[col_name].value_counts(normalize=True, sort=True)\n","    \n","    # Plot the graphs\n","    fig4 = plt.figure(figsize=(20,7))\n","    fig4.suptitle(\"Profile of column  \" + col_name, fontsize=25)  #Title for the whole figure\n","    plt.subplots_adjust(wspace=0.4, hspace=0.35, bottom=0.35)\n","\n","    ax1 = fig4.add_subplot(1,1,1)\n","    ax1.set_title(\"Bar chart for top 25 values\", fontsize=20)\n","    plt.setp(ax1.get_xticklabels(), ha=\"right\", rotation=45, fontsize=15)\n","    plt.setp(ax1.get_yticklabels(), ha=\"right\", fontsize=15)\n","    \n","    col_unique_vals.head(values_freq_threshold).sort_values(ascending=False).plot.bar()\n","    plt.xticks(rotation=75)\n","    for p in ax1.patches:\n","        ax1.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.005, p.get_height() * 1.005), fontsize=15)\n","    \n","    fig4.suptitle(\"Profile of column  \" + col_name, fontsize=25)  #Title for the whole figure\n","    fig_name = 'fig_' + col_name\n","    fig4.savefig(fig_name, dpi= 50)\n","\n","    plt.close('all')\n","#     plt.show()"],"execution_count":36,"outputs":[{"output_type":"stream","text":["1  of  38  completed    p_6\n","2  of  38  completed    p_7\n","3  of  38  completed    p_10\n","4  of  38  completed    p_43a\n","5  of  38  completed    p_43b\n","6  of  38  completed    p_43c\n","7  of  38  completed    p_43d\n","8  of  38  completed    p_146\n","9  of  38  completed    p_147\n","10  of  38  completed    p_148\n","11  of  38  completed    p_158\n","12  of  38  completed    p_162\n","13  of  38  completed    p_165\n","14  of  38  completed    p_171\n","15  of  38  completed    p_174\n","16  of  38  completed    p_178\n","17  of  38  completed    p_184\n","18  of  38  completed    p_258\n","19  of  38  completed    p_259\n","20  of  38  completed    p_260\n","21  of  38  completed    p_281\n","22  of  38  completed    p_282\n","23  of  38  completed    p_283\n","24  of  38  completed    p_284\n","25  of  38  completed    p_285\n","26  of  38  completed    p_286\n","27  of  38  completed    p_312\n","28  of  38  completed    p_313\n","29  of  38  completed    p_314\n","30  of  38  completed    p_315\n","31  of  38  completed    p_316\n","32  of  38  completed    p_317\n","33  of  38  completed    p_318\n","34  of  38  completed    p_319\n","35  of  38  completed    p_320\n","36  of  38  completed    p_321\n","37  of  38  completed    p_322\n","38  of  38  completed    p_323\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4wPsue57YGIV","colab_type":"text"},"source":["# Candidate columns for Category type"]},{"cell_type":"markdown","metadata":{"id":"8x2ArGNLYGIW","colab_type":"text"},"source":["Analysing how many unique values an 'object' column has will be useful to detrmine which columns are good candidates for *Categorical* data type. In combination with the total memory used by 'object' data type and each 'object' data type column, decisions can be made on converting them Category type."]},{"cell_type":"code","metadata":{"id":"Fkp7rl8VYGIW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938201063,"user_tz":300,"elapsed":1231,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Create a df and a column for % of memory by each object column\n","cardn_df = data_qlt_df[data_qlt_df['col_data_type'] == 'object'][['column_name', 'col_memory', '%_of_dtype_mem', '%_of_total_memory', 'unique_values_count']]\n","\n","cardn_df = cardn_df.sort_values('unique_values_count')\n"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-WomD6dzYGIZ","colab_type":"text"},"source":["# Candidate columns for down casting type"]},{"cell_type":"code","metadata":{"id":"5FdO8fL8YGIa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938205149,"user_tz":300,"elapsed":870,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Create a df and a column for % of memory by each object column\n","num_cardn_df = data_qlt_df[data_qlt_df['col_data_type'] != 'object'][['column_name', 'col_memory', '%_of_dtype_mem', '%_of_total_memory', 'unique_values_count']]\n","\n","num_cardn_df = num_cardn_df.sort_values('unique_values_count')"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z1tqVx-fYGId","colab_type":"text"},"source":["# Columns with high percentage of null values"]},{"cell_type":"code","metadata":{"id":"vx3y_73JYGIe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938207125,"user_tz":300,"elapsed":752,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# The empty values threshold can be set to a lower/higher value depending on the size of the data sets \n","threshold_perc = 0.75\n","col_vals_threshold = df.shape[0] * threshold_perc"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ft0OclnxYGIj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938209148,"user_tz":300,"elapsed":1082,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["null_vals_df = data_qlt_df[data_qlt_df['non_null_values'] < col_vals_threshold][['column_name', 'col_data_type', 'col_memory', 'non_null_values', '%_of_non_nulls', 'null_values', '%_of_nulls']]\n","\n","# .style.format({'dtype_memory': \"{:,.2f}\", 'non_null_values': \"{:,.2f}\", '%_of_non_nulls': \"{:,.2f}\", 'null_values': \"{:,.2f}\", '%_of_nulls': \"{:,.2f}\",  'unique_values_count': \"{:,.2f}\"})"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ypZjLTE5YGIm","colab_type":"text"},"source":["# Generate the Correlation plot"]},{"cell_type":"code","metadata":{"id":"k8WKHZd_YGIn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938211321,"user_tz":300,"elapsed":1542,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["f, ax = plt.subplots(figsize=(15, 10))\n","plt.subplots_adjust(bottom=0.35)\n","plt.autoscale()\n","\n","corr_data = df.corr()\n","sns.heatmap(corr_data,\n","            mask=np.zeros_like(corr_data, dtype=np.bool), \n","            cmap=sns.diverging_palette(20, 220, as_cmap=True),\n","            vmin=-1, vmax=1,\n","            square=True, \n","            ax=ax)\n","\n","fig_name = 'fig_cor_plot.png'\n","f.savefig(fig_name,  dpi=70)\n","# plt.show()\n","plt.close('all')"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5SJgBz80YGIq","colab_type":"text"},"source":["### Importing the image for the document"]},{"cell_type":"code","metadata":{"id":"bmdgtJQ-YGIr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938213473,"user_tz":300,"elapsed":1528,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["import requests\n","\n","image_url = \"https://raw.githubusercontent.com/AnalyticsInsightsNinja/Python_TidyData/master/SAMPLE_FULL_DPD_Image_MSWORD.PNG\"\n","\n","Picture_request = requests.get(image_url)\n","if Picture_request.status_code == 200:\n","    with open(\"msword_output.jpg\", 'wb') as f:\n","        f.write(Picture_request.content)"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3msx-SyAYGIu","colab_type":"text"},"source":["# Construct the MS Word document"]},{"cell_type":"code","metadata":{"id":"QbxQtDuWYGIv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938214060,"user_tz":300,"elapsed":1301,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Make sure you have the docx package and it is imported\n","# see the environment setup section\n","\n","#Create Document object\n","document = Document()\n","\n","# Add Title\n","document.add_heading('Data Profile Dataframe - Notebook v0.17 - 14 July 2019', 0)\n","document.add_heading(raw_data_file, 0)\n","\n","# COver page paragraph\n","p = document.add_paragraph('The main objective of this notebook is ')\n","p.add_run('only').bold = True\n","p.add_run(' to understand raw data profile. i.e. data type, min & max values, ranges, unique values, etc.')\n","p = document.add_paragraph('In consequent notebooks we will explore further on how to make decisions to make \\\n","the data tidy and perform the data transformations based on the understanding of the data profile.')\n","p = document.add_paragraph('')\n","p.add_run('The code is largely kept generic so that it could be used with any shape of data.').italic = True\n"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"A5LIfcDQYGIz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592938214062,"user_tz":300,"elapsed":904,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"53d6205f-790d-4df6-8cf3-d004e60e9c76"},"source":["# Page 2\n","document.add_page_break()\n","# Heading 1\n","document.add_heading('The Game Changer - Data Profile Dataframe (DPD)', level=1)\n","p = document.add_paragraph('The game changer for exploratory data analysis is the final')\n","p.add_run(' Data Profile Dataframe').bold = True\n","p.add_run(' that is generated which combines ')\n","p.add_run('all').bold = True\n","p.add_run(' the information required to inform data cleaning, tidy data and optimisations (memory and processing) decisions.\\\n"," Instead of using various Pandas commands at different instances and going back and forth to cross refer information, Data Profile Dataframe brings all information into a single dataframe.\\\n"," This will be very useful when reviewing the data profile with the business subject matter or other team members as all information related to data profile is in a single easy to understand format.')\n","\n","document.add_picture('msword_output.jpg', height=Inches(4), width=Inches(4))\n","\n","document.add_page_break()\n","p = document.add_paragraph('Understanding the data is ')\n","p.add_run('the critical step').bold = True\n","p.add_run(' in preparing the data to be used for analytics.\\\n"," As many experts will point out the data preparation and transforming the data into a tidy format takes about 80% of the effort in any data analytics or data analysis project.')\n","p = document.add_paragraph('')\n","p.add_run('Understanding the data requires good understanding of the domain and/or access to a subject\\\n","matter expert (SME) to help make decisions about data quality and data usage:').bold = True\n","\n","document.add_paragraph(\n","    'What are the columns and what do they mean?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'How to interpret each columns and possible values of a column?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'Should the columns be renamed (and cleaned e.g. trim)?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'Are there columns that may have similar information that could be dropped in favour of one master column?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'Can columns with no values (or all empty) be dropped?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'Can columns which have more than certain threshold of blank values be dropped?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'Can rows that have missing values for certain columns or combination of columns be dropped?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'i.e. the row is meaningless wihtout those values.', style='List Continue'\n",")\n","document.add_paragraph(\n","    'Can the numeric data type columns be converted / down casted to optimise memory usage based on the data values?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'or will there be outliers possibly in future data sets that we cannot do this?', style='List Bullet 2'\n",")\n","document.add_paragraph(\n","    'Can the min and max values be used to determine the lowest possible data type?', style='List Bullet 2'\n",")\n","document.add_paragraph(\n","    'Can some string/object columns be converted to Category types?', style='List Bullet'\n",")\n","document.add_paragraph(\n","    'based on count of unique values', style='List Bullet 2'\n",")\n","document.add_paragraph(\n","    'Can any columns be discarded that may not be required for analytics?', style='List Bullet'\n",")\n"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<docx.text.paragraph.Paragraph at 0x7fa84cab4a20>"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"Abv6dI8MYGI-","colab_type":"text"},"source":["# Word - Data profile summary"]},{"cell_type":"code","metadata":{"id":"P8siMwESYGI_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592938217158,"user_tz":300,"elapsed":1869,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"c2a3ec3d-fa36-45ea-9ca9-20f8dcab906d"},"source":["document.add_page_break()\n","document.add_heading('Columns Data Profile Summary', 0)"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<docx.text.paragraph.Paragraph at 0x7fa84c2ce278>"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"-ZS9g6vZYGJI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938217162,"user_tz":300,"elapsed":1304,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Page 4\n","p = document.add_paragraph(' ')\n","\n","# Heading 1\n","document.add_heading('Dataset shape', level=1)\n","\n","table = document.add_table(rows=2, cols=2, style = 'Medium Shading 1 Accent 3')\n","\n","# Header row\n","cell = table.cell(0, 0)\n","cell.text = 'No.of rows'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = True\n","\n","cell = table.cell(0, 1)\n","cell.text = 'No.of columns'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = True\n","\n","# Values\n","cell = table.cell(1, 0)\n","cell.text = F'{df.shape[0] :,}'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = False\n","\n","cell = table.cell(1, 1)\n","cell.text = F'{df.shape[1] :,}'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = False\n"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"874wAIlRYGJP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938221648,"user_tz":300,"elapsed":5577,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Page 4a\n","# document.add_page_break()\n","p = document.add_paragraph(' ')\n","\n","# Heading 1\n","document.add_heading('Dataframe columns summary', level=1)\n","\n","# Rehsape the column data type dataframe into form that can be printed in MS Word\n","data = round(data_qlt_df[['column_name','col_data_type', 'non_null_values', 'null_values', 'count']], 2)\n","\n","# add a table to the end and create a reference variable\n","# extra row is so we can add the header row\n","table = document.add_table(data.shape[0]+1, data.shape[1], style='Medium Shading 1 Accent 3')\n","\n","# add the header rows.\n","for j in range(data.shape[1]):\n","\n","    #header row first two columns\n","    if j <= 1:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","    else:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","        cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT\n","        \n","    \n","# add the rest of the data frame\n","for i in range(data.shape[0]):\n","    for j in range(data.shape[1]):\n","        if j <= 1:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j]}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False            \n","        else:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j] :,}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False  \n","            cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT           \n"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AP_2EZyIYGJY","colab_type":"text"},"source":["# Word - Column memory usage profile"]},{"cell_type":"code","metadata":{"id":"mOPOs3ZpYGJZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592938221650,"user_tz":300,"elapsed":4672,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"c0ac15e7-9977-4be9-9c35-f714765336f7"},"source":["document.add_page_break()\n","document.add_heading('Memory Usage Profile', 0)"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<docx.text.paragraph.Paragraph at 0x7fa84c2eacc0>"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"yuo08JAVYGJh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592938221652,"user_tz":300,"elapsed":3893,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"bc66bb48-2dbf-45ac-c3d0-9fcd1ee0e33d"},"source":["# Page 5\n","p = document.add_paragraph(' ')\n","\n","# Heading 1\n","document.add_heading('Data file size on disk vs. dataset size in memory', level=1)\n","\n","# Create table\n","table = document.add_table(rows=3, cols=2, style = 'Medium Shading 1 Accent 3')\n","\n","# Add column headers\n","cell = table.cell(0,0)\n","cell.text = 'Description'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = True  \n","\n","cell = table.cell(0,1)\n","cell.text = 'Size in MB'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = True  \n","cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT \n","\n","# Add values : Value Line 1\n","cell = table.cell(1,0)\n","cell.text = 'Data file size on disk'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = False  \n","\n","cell = table.cell(1,1)\n","cell.text = F'{round(file_size, 2)  :,.2f}'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = False  \n","cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT \n","\n","# Add values : Value Line 2\n","cell = table.cell(2,0)\n","cell.text = 'Dataset size in memory'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = False  \n","\n","cell = table.cell(2,1)\n","cell.text = F'{round(df_mem, 2)  :,.2f}'\n","cell_font = cell.paragraphs[0].runs[0].font\n","cell_font.size = Pt(11)\n","cell_font.bold = False  \n","cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT \n","\n","# Memory increase\n","p = document.add_paragraph('')\n","p = document.add_paragraph('Dataset increase in memory :  ')\n","p.add_run(str(round(sz_increase*100, 2)) + '%').bold = True\n","\n","# Add graph\n","document.add_picture('fig_df_tot_memory.png', height=Inches(3), width=Inches(3))\n"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<docx.shape.InlineShape at 0x7fa84d0aab70>"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"Itv438CDYGJl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938221653,"user_tz":300,"elapsed":3664,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Page 6\n","document.add_page_break()\n","\n","# Heading 1\n","document.add_heading('Dataframe column types and size in memory', level=1)\n","\n","# Rehsape the column data type dataframe into form that can be printed in MS Word\n","# Using .reset_index() will make the index a column\n","data = round(plt_dtype.reset_index(), 2)\n","\n","\n","# add a table to the end and create a reference variable\n","# extra row is so we can add the header row\n","table = document.add_table(data.shape[0]+1, data.shape[1], style = 'Medium Shading 1 Accent 3')\n","\n","# add the header rows.\n","for j in range(data.shape[1]):\n","    #header row first first columns\n","    if j == 0:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","    else:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","        cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT\n","        \n","    \n","# add the rest of the data frame\n","for i in range(data.shape[0]):\n","    for j in range(data.shape[1]):\n","        if j == 0:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j]}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False            \n","        else:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j] :,.2f}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False  \n","            cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT           \n","\n","\n","p = document.add_paragraph(' ')\n","p = document.add_paragraph('\"col_data_type\" : Column data type')\n","p = document.add_paragraph('\"dtype_count\" : Number of oclumns in the dataset of the given data type')\n","p = document.add_paragraph('\"dtype_total\" : Total memory in MB for the given data type')\n","p = document.add_paragraph('\"dtype_%_total_mem\" : Percentage of the memory used by the given data type out of the total memory used by the dataset')\n","\n","document.add_picture('fig_cols_memory.png', height=Inches(3), width=Inches(6))\n","\n","p = document.add_paragraph('In a memory heavy datasets the above information can shed light into which data type you need to focus if you need to optimise the memory usage.')\n","p = document.add_paragraph('e.g. may be convert \"object\" datatype to \"category\" type if the cardinality is low or may be down cast \"float64\" to float16 or smaller.')\n","p = document.add_paragraph('These decision need further information on column cardinality and max/min values which are covered in the next few sections.')\n"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"6rDHIiGhYGJo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938222890,"user_tz":300,"elapsed":4538,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Page 7\n","document.add_page_break()\n","\n","# Heading 1\n","document.add_heading('Memory used by \"object\" data type', level=1)\n","\n","\n","# Rehsape the column data type dataframe into form that can be printed in MS Word\n","# Using .reset_index() will make the index a column\n","data = round(cardn_df.sort_values(\"unique_values_count\"), 2)\n","\n","\n","# add a table to the end and create a reference variable\n","# extra row is so we can add the header row\n","table = document.add_table(data.shape[0]+1, data.shape[1], style = 'Medium Shading 1 Accent 3')\n","\n","# add the header rows.\n","for j in range(data.shape[1]):\n","    #header row first first columns\n","    if j == 0:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","    else:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","        cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT\n","        \n","    \n","# add the rest of the data frame\n","for i in range(data.shape[0]):\n","    for j in range(data.shape[1]):\n","        if j == 0:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j]}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False            \n","        else:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j] :,.2f}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False  \n","            cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT           \n","\n","\n","p = document.add_paragraph(' ')\n","p = document.add_paragraph('\"column_name\" : Name of the column in the dataframe')\n","p = document.add_paragraph('\"col_memory\" : Memory used by the given column')\n","p = document.add_paragraph('\"%_of_dtype_mem\" : Percentage of memory used by the given column out of memory used by the column data type')\n","p = document.add_paragraph('\"%_of_total_memory\" : Percentage of the memory used by the given column out of the total memory used by the dataset')\n","p = document.add_paragraph('\"unique_values_count\" : Count of the unique values for the given column')\n","\n","document.add_picture('fig_object_cols_memory.png', height=Inches(3), width=Inches(6))\n","\n","p = document.add_paragraph(' ')\n","p = document.add_paragraph(\"Analysing how many unique values an 'object' column has will be useful to detrmine\\\n","which columns are good candidates for *Categorical* data type. In combination with the total memory used by 'object'\\\n","data type and each 'object' data type column, decisions can be made on converting them Category type.\\\n","Object or string data type columns with low cardinality is suitable for Category type.\")\n","p.add_run(\"The threshold of 'low cardinality' depends on the domain of the data and data usage patterns.\").bold = True"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZaV88-sYGJu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938224740,"user_tz":300,"elapsed":5799,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Page 8\n","document.add_page_break()\n","\n","# Heading 1\n","document.add_heading('Memory used by \"Non-Object\" data type', level=1)\n","\n","# Rehsape the column data type dataframe into form that can be printed in MS Word\n","# Using .reset_index() will make the index a column\n","data = round(num_cardn_df.sort_values(\"unique_values_count\"), 2)\n","\n","# add a table to the end and create a reference variable\n","# extra row is so we can add the header row\n","table = document.add_table(data.shape[0]+1, data.shape[1], style = 'Medium Shading 1 Accent 3')\n","\n","# add the header rows.\n","for j in range(data.shape[1]):\n","    #header row first first columns\n","    if j == 0:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","    else:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","        cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT\n","        \n","    \n","# add the rest of the data frame\n","for i in range(data.shape[0]):\n","    for j in range(data.shape[1]):\n","        if j == 0:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j]}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False            \n","        else:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j] :,.2f}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False  \n","            cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT           \n","\n","\n","p = document.add_paragraph(' ')\n","p = document.add_paragraph('\"column_name\" : Name of the column in the dataframe')\n","p = document.add_paragraph('\"col_memory\" : Memory used by the given column')\n","p = document.add_paragraph('\"%_of_dtype_mem\" : Percentage of memory used by the given column out of memory used by the column data type')\n","p = document.add_paragraph('\"%_of_total_memory\" : Percentage of the memory used by the given column out of the total memory used by the dataset')\n","\n","document.add_picture('fig_non_object_cols_memory.png', height=Inches(3), width=Inches(6))\n","\n","p = document.add_paragraph(' ')\n","p = document.add_paragraph(\"By analysing the min and max values of the numeric columns decions can be made to downcast the data type to more memory efficient storage types.\")\n"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"-cCFoc0lYGJx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938224742,"user_tz":300,"elapsed":3925,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# Page 9\n","document.add_page_break()\n","\n","# Heading 1\n","document.add_heading('Columns with non-null values less than ' + \"{:,.2f}\".format(threshold_perc*100) + '%', level=1)\n","\n","p = document.add_paragraph('The columns should contain at least  ' + \"{:,.0f}\".format(col_vals_threshold) + '  (' + \"{:,.2f}\".format((col_vals_threshold/df.shape[0])*100) + '%) non-empty rows out of  '+ \"{:,}\".format(df.shape[0]) + ' rows to be considered useful.')\n","p = document.add_paragraph('The non-empty values threshold can be set using the threshold_perc variable in the code.')\n","\n","\n","# Rehsape the column data type dataframe into form that can be printed in MS Word\n","# Using .reset_index() will make the index a column\n","data = round(null_vals_df.sort_values(\"non_null_values\"), 2)\n","\n","# add a table to the end and create a reference variable\n","# extra row is so we can add the header row\n","table = document.add_table(data.shape[0]+1, data.shape[1], style = 'Medium Shading 1 Accent 3')\n","\n","# add the header rows.\n","for j in range(data.shape[1]):\n","    #header row first first columns\n","    if j <= 1:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","    else:\n","        cell = table.cell(0, j)\n","        cell.text = F'{data.columns[j]}'\n","        cell_font = cell.paragraphs[0].runs[0].font\n","        cell_font.size = Pt(11)\n","        cell_font.bold = True\n","        cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT\n","        \n","    \n","# add the rest of the data frame\n","for i in range(data.shape[0]):\n","    for j in range(data.shape[1]):\n","        if j <= 1:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j]}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False            \n","        else:\n","            cell = table.cell(i+1, j)\n","            cell.text = F'{data.values[i,j] :,.2f}'\n","            cell_font = cell.paragraphs[0].runs[0].font\n","            cell_font.size = Pt(11)\n","            cell_font.bold = False  \n","            cell.paragraphs[0].alignment= WD_ALIGN_PARAGRAPH.RIGHT           \n","        \n","\n","\n","p = document.add_paragraph(' ')\n","p = document.add_paragraph('\"column_name\" : Name of the column in the dataframe')\n","p = document.add_paragraph('\"col_data_type\" : Data type of the given column')\n","p = document.add_paragraph('\"col_memory\" : Memory used by the given column')\n","p = document.add_paragraph('\"non_null_values\" : Count of non-null values in the given column')\n","p = document.add_paragraph('\"%_of_non_nulls\" : Percentage of the non-null values out of total values for the given column')\n","p = document.add_paragraph('\"null_values\" : Count of null values in the given column')\n","p = document.add_paragraph('\"%_of_nulls\" : Percentage of the null values out of total values for the given column')\n","\n","p = document.add_paragraph(' ')\n","p = document.add_paragraph(\"Generally columns with large percentage of empty values can be *dropped* from the dataset as they will not add any value to the analysis.\")\n","p = document.add_paragraph('')\n","p.add_run('But this depends on the domian of the dataset and usage pattern of the columns/data.').bold = True\n"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cX4ohFHBYGJ2","colab_type":"text"},"source":["# Word - Data Correlation plot"]},{"cell_type":"code","metadata":{"id":"bjcxr-Y-YGJ3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592938224746,"user_tz":300,"elapsed":1338,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"91d53dde-c3bc-48fa-c59d-fe59a8be14c3"},"source":["document.add_page_break()\n","document.add_heading('Data correlation plot', 0)\n","\n","p = document.add_paragraph('')\n","\n","document.add_picture('fig_cor_plot.png', height=Inches(6), width=Inches(6))"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<docx.shape.InlineShape at 0x7fa84c2e06d8>"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"markdown","metadata":{"id":"jiQlcs_JYGJ8","colab_type":"text"},"source":["# Word - Create the detail column profile rows"]},{"cell_type":"code","metadata":{"id":"tblD57wgYGJ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592938227572,"user_tz":300,"elapsed":1932,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"4b61371a-200d-4f6a-e1a5-34ef28fce92d"},"source":["document.add_page_break()\n","document.add_heading('Column Data Profile Details', 0)"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<docx.text.paragraph.Paragraph at 0x7fa84c2c3668>"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"M3-0gpKLYGKB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938237901,"user_tz":300,"elapsed":11466,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":[" import pathlib\n","# ind = 1  # to be taken from iterrows loop later\n","for ind in range(data_qlt_df.shape[0]):\n","    document.add_page_break()\n","    \n","    # Create table for column profile details\n","    table = document.add_table(rows=6, cols=6, style = 'Medium Shading 1 Accent 3' )\n","    \n","    # Merge cells in header row for COlumn Name\n","    for y in range(len(table.rows[0].cells)-1):\n","        a = table.cell(0,y)\n","        b = table.cell(0,y+1)\n","        a.merge(b)\n","\n","    # Merge cells in detail rows spanning 2 cells x 3 \n","    for row in range(1,6):\n","        a = table.cell(row,0)\n","        b = table.cell(row,1)\n","        a.merge(b)\n","        a = table.cell(row,2)\n","        b = table.cell(row,3)\n","        a.merge(b)\n","        a = table.cell(row,4)\n","        b = table.cell(row,5)\n","        a.merge(b)\n","\n","\n","    #*** ADD VALUES TO TABLE  ***#\n","    # Cell 0,0 (merged 6 cells): Header - Column Name\n","    cell = table.cell(0, 0)\n","    cell.text = data_qlt_df[\"column_name\"][ind]\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(15)\n","    cell_font.bold = True\n","\n","    # Cell 1,0: Blank\n","    cell = table.cell(1, 1)\n","    cell.text = \"TBD Column :\\n\"\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run('no value')\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(12)\n","    cell_font2.bold = False\n","\n","    # Cell 1,0: Column data type\n","    cell = table.cell(1, 3)\n","    cell.text = 'Data Type : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(str(data_qlt_df[\"col_data_type\"][ind]))\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(12)\n","    cell_font2.bold = False\n","\n","    # Cell 1,1: Count of toal values in the column\n","    cell = table.cell(1, 5)\n","    cell.text = 'Values Count : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"count\"][ind] :,.0f}')\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 2,0: Count of unique values in the column\n","    cell = table.cell(2, 1)\n","    cell.text = 'Unique Values Count : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    unique_per = (data_qlt_df[\"unique_values_count\"][ind] / data_qlt_df[\"count\"][ind]) * 100\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"unique_values_count\"][ind] :,.0f}' + \"   \" + F'({unique_per :,.2f}%)' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 2,1: Count of non-null values in the column\n","    cell = table.cell(2, 3)\n","    cell.text = 'Non-Null Values Count : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"non_null_values\"][ind] :,.0f}' + \"   \" + F' ({data_qlt_df[\"%_of_non_nulls\"][ind]  :,.2f}%)' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False       \n","\n","    # Cell 2,2: Count of null values in the column\n","    cell = table.cell(2, 5)\n","    cell.text = 'Null Values Count : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"null_values\"][ind]  :,.0f}' + \"   \" + F' ({data_qlt_df[\"%_of_nulls\"][ind]  :,.2f}%)' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 3,0: Min of values in the column\n","    cell = table.cell(3, 1)\n","    cell.text = 'Min : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"min\"][ind]  :,.2f}' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 3,1: Mean of values in the column\n","    cell = table.cell(3, 3)\n","    cell.text = 'Mean :  \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"mean\"][ind] :,.2f}' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 3,3: Max of values in the column\n","    cell = table.cell(3, 5)\n","    cell.text = 'Max : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"max\"][ind]  :,.2f}' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 4,1: 25th Percentile of values in the column\n","    cell = table.cell(4, 1)\n","    cell.text = '25th Percentile : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"25%\"][ind]  :,.2f}' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 4,2: 50th Percentile of values in the column\n","    cell = table.cell(4, 3)\n","    cell.text = '50th Percentile : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"50%\"][ind]  :,.2f}' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 4,3: 75th Percentile of values in the column\n","    cell = table.cell(4, 5)\n","    cell.text = '75th Percentile : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"75%\"][ind]  :,.2f}' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 5,1: Memory used by the column values\n","    cell = table.cell(5, 1)\n","    cell.text = 'Column Memory : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"col_memory\"][ind] :,.2} MB' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    # Cell 5,2: Memory used by the column values vs. memory used by the data type\n","    cell = table.cell(5, 3)\n","    cell.text = 'As % of Dtype Memory  : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"%_of_dtype_mem\"][ind] :.2f}%' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False                               \n","\n","    # Cell 5,3: Memory used by the column values vs. memory used by the data type\n","    cell = table.cell(5, 5)\n","    cell.text = 'As % of DF Memory : \\n'\n","    cell_font = cell.paragraphs[0].runs[0].font\n","    cell_font.size = Pt(11)\n","    cell_font.bold = True\n","    p = cell.paragraphs[0].add_run(F'{data_qlt_df[\"%_of_total_memory\"][ind] :.2f}%' )\n","    cell_font2 = cell.paragraphs[0].runs[1].font\n","    cell_font2.size = Pt(11)\n","    cell_font2.bold = False\n","\n","    p = document.add_paragraph(' ')\n","    p = document.add_paragraph(' ')\n","\n","    fig_name = 'fig_' + data_qlt_df['column_name'][ind] + '.png'\n","    \n","    #validar si la imagen existe, si no, NULL\n","    file = pathlib.Path(fig_name)\n","    if file.exists ():\n","        document.add_picture(fig_name, height=Inches(3.5), width=Inches(6))\n","    else:\n","        document.add_picture('Null.png', height=Inches(3.5), width=Inches(6))         \n"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JORHD-eYGKF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592938237904,"user_tz":300,"elapsed":8993,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}}},"source":["# save the doc\n","document.save('/content/gdrive/My Drive/calidad_de_vida_medellin/outputs/perfilado_T2_ECV_sindum_sinout_ord.docx')"],"execution_count":57,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sa2-9z88eVlT","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"-Z8hjjDmYGKJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592938237909,"user_tz":300,"elapsed":6217,"user":{"displayName":"Susana Londoño","photoUrl":"","userId":"14878614664395617791"}},"outputId":"bfcab6ab-fae1-4931-98a6-d1909327b19b"},"source":["print(\"Document generated!\")"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Document generated!\n"],"name":"stdout"}]}]}